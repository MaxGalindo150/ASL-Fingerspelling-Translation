{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Processing Data for Model_0 (Neural Network)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load the necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np \n","import json"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T03:43:02.666218Z","iopub.status.busy":"2023-06-06T03:43:02.665845Z","iopub.status.idle":"2023-06-06T03:43:02.827768Z","shell.execute_reply":"2023-06-06T03:43:02.826644Z","shell.execute_reply.started":"2023-06-06T03:43:02.666188Z"},"trusted":true},"outputs":[],"source":["BASE_DIR = '../input/asl-fingerspelling'\n","\n","train = pd.read_csv(f'{BASE_DIR}/train.csv')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Remove pose and face columns "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Due to the computational power restrictions, we will only analyze 9 of the provided Parquet files, which amounts to approximately 9,000 sentences.**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T03:43:03.890094Z","iopub.status.busy":"2023-06-06T03:43:03.889689Z","iopub.status.idle":"2023-06-06T03:43:03.895143Z","shell.execute_reply":"2023-06-06T03:43:03.894084Z","shell.execute_reply.started":"2023-06-06T03:43:03.890059Z"},"trusted":true},"outputs":[],"source":["parquet_files = ['train_landmarks/1134756332.parquet',\n"," 'train_landmarks/5414471.parquet',\n"," 'train_landmarks/1664666588.parquet',\n"," 'train_landmarks/1133664520.parquet',\n"," 'train_landmarks/234418913.parquet',\n"," 'train_landmarks/566963657.parquet',\n"," 'train_landmarks/1920330615.parquet',\n"," 'train_landmarks/105143404.parquet',\n"," 'train_landmarks/933868835.parquet']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**We keep each dataframe corresponding to each parquet file in a list called 'dataframes'**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T03:43:05.594375Z","iopub.status.busy":"2023-06-06T03:43:05.593746Z","iopub.status.idle":"2023-06-06T03:45:29.069965Z","shell.execute_reply":"2023-06-06T03:45:29.068448Z","shell.execute_reply.started":"2023-06-06T03:43:05.594342Z"},"trusted":true},"outputs":[],"source":["dataframes = []\n","\n","# Iterar sobre cada archivo parquet\n","for file in parquet_files:\n","    # Leer el archivo parquet en un DataFrame\n","    df = pd.read_parquet(f'{BASE_DIR}/{file}')\n","\n","    # Agregar el DataFrame a la lista\n","    dataframes.append(df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**We removed some columns.**"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T03:45:48.672567Z","iopub.status.busy":"2023-06-06T03:45:48.672175Z","iopub.status.idle":"2023-06-06T03:45:49.128350Z","shell.execute_reply":"2023-06-06T03:45:49.127070Z","shell.execute_reply.started":"2023-06-06T03:45:48.672538Z"},"trusted":true},"outputs":[],"source":["columns = ['x_pose_', 'y_pose_', 'z_pose_', 'x_face_', 'y_face_', 'z_face_']\n","\n","for i in range(len(dataframes)):\n","    dataframes[i] = dataframes[i].drop(columns=[col for col in dataframes[i].columns if any(col.startswith(column) for column in columns)])\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**There are sentences that correspond to only a single frame, we will remove these sentences from our analysis as they are likely errors. It doesn't make sense for a lengthy phrase like a phone number to consist of a single sign language gesture. We will filter only those sentences that have more than 300 frames.**"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T03:45:51.962079Z","iopub.status.busy":"2023-06-06T03:45:51.961578Z","iopub.status.idle":"2023-06-06T03:45:52.772604Z","shell.execute_reply":"2023-06-06T03:45:52.771439Z","shell.execute_reply.started":"2023-06-06T03:45:51.962043Z"},"trusted":true},"outputs":[],"source":["for i in range(0,9):\n","    index_count = dataframes[i].index.value_counts()\n","\n","    # Filtrar los índices que se repiten 300 o más veces\n","    filtered_indices = index_count[index_count >= 300].index\n","\n","    # Filtrar el dataframe original\n","    dataframes[i] = dataframes[i].groupby(dataframes[i].index).filter(lambda x: x.index[0] in filtered_indices)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**We equalized the number of frames for each landmark sequence to 720 frames.**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:27:33.965536Z","iopub.status.busy":"2023-06-06T00:27:33.964912Z","iopub.status.idle":"2023-06-06T00:27:50.576773Z","shell.execute_reply":"2023-06-06T00:27:50.575683Z","shell.execute_reply.started":"2023-06-06T00:27:33.965490Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n"]}],"source":[" for i in range(9):\n","    sequence_id = dataframes[i].index.unique()\n","    for j in range(len(sequence_id)):\n","        current_frames = dataframes[i].index.value_counts()[sequence_id[j]]\n","        num_new_rows = 720 - current_frames\n","        if num_new_rows > 0:\n","            new_rows = pd.DataFrame([[current_frames + 1 + k] + [0] * 84 for k in range(num_new_rows)],\n","                                    columns=dataframes[0].columns, index=[sequence_id[j]] * num_new_rows)\n","            dataframes[i] = pd.concat([dataframes[i], new_rows], axis=0, ignore_index=False)\n","            \n","    print(i)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Remove null values**"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:28:14.212770Z","iopub.status.busy":"2023-06-06T00:28:14.211536Z","iopub.status.idle":"2023-06-06T00:28:14.364136Z","shell.execute_reply":"2023-06-06T00:28:14.362505Z","shell.execute_reply.started":"2023-06-06T00:28:14.212720Z"},"trusted":true},"outputs":[],"source":["for i in range(9):\n","    dataframes[i] = dataframes[i].fillna(0)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:28:16.114346Z","iopub.status.busy":"2023-06-06T00:28:16.113847Z","iopub.status.idle":"2023-06-06T00:28:16.326388Z","shell.execute_reply":"2023-06-06T00:28:16.324924Z","shell.execute_reply.started":"2023-06-06T00:28:16.114301Z"},"trusted":true},"outputs":[],"source":["dataframe = pd.concat(dataframes, ignore_index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Relating each phrase to its respective dataframe"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Creating a dictionary with the identifiers of each phrase as key and as values the corresponding dataframe.**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:28:17.593052Z","iopub.status.busy":"2023-06-06T00:28:17.592600Z","iopub.status.idle":"2023-06-06T00:28:18.191515Z","shell.execute_reply":"2023-06-06T00:28:18.190428Z","shell.execute_reply.started":"2023-06-06T00:28:17.593020Z"},"trusted":true},"outputs":[],"source":["dataframe_dict = {}\n","for sequence_id in dataframe.index.unique():\n","    dataframe_dict[sequence_id] = dataframe.loc[sequence_id]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create a list to store the landmark dataframes and another list to store the corresponding phrases in the same order."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:28:25.585340Z","iopub.status.busy":"2023-06-06T00:28:25.584859Z","iopub.status.idle":"2023-06-06T00:28:25.596240Z","shell.execute_reply":"2023-06-06T00:28:25.594721Z","shell.execute_reply.started":"2023-06-06T00:28:25.585300Z"},"trusted":true},"outputs":[],"source":["indices = dataframe.index.unique()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:28:32.224848Z","iopub.status.busy":"2023-06-06T00:28:32.223696Z","iopub.status.idle":"2023-06-06T00:28:33.855817Z","shell.execute_reply":"2023-06-06T00:28:33.854796Z","shell.execute_reply.started":"2023-06-06T00:28:32.224802Z"},"trusted":true},"outputs":[],"source":["phrases = []\n","for index_phrase in indices:\n","    phrase = train.query(f'sequence_id=={index_phrase}')['phrase'].values[0]\n","    phrases.append(phrase)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:28:36.114878Z","iopub.status.busy":"2023-06-06T00:28:36.114450Z","iopub.status.idle":"2023-06-06T00:28:36.122054Z","shell.execute_reply":"2023-06-06T00:28:36.120764Z","shell.execute_reply.started":"2023-06-06T00:28:36.114844Z"},"trusted":true},"outputs":[],"source":["sequence_phrase = {}\n","for i in range(len(phrases)):\n","    sequence_id_phrase = indices[i] # Identificador de la secuencia\n","    phrase = phrases[i]\n","    sequence_phrase[sequence_id_phrase] = phrase"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:28:38.227563Z","iopub.status.busy":"2023-06-06T00:28:38.227095Z","iopub.status.idle":"2023-06-06T00:28:38.665174Z","shell.execute_reply":"2023-06-06T00:28:38.663833Z","shell.execute_reply.started":"2023-06-06T00:28:38.227529Z"},"trusted":true},"outputs":[],"source":["landmarks_data = []  # Lista para almacenar los dataframes de landmarks\n","phrase_order = []  # Lista para mantener el orden de las frases\n","\n","# Iterar sobre los sequence_id\n","for sequence_id, dataframe in dataframe_dict.items():\n","    landmarks_dataframe = dataframe.iloc[:, 1:]  # Seleccionar todas las columnas excepto la última (frames)\n","    landmarks_data.append(landmarks_dataframe)\n","    phrase = sequence_phrase.get(sequence_id)  # Obtener la frase correspondiente al sequence_id\n","    phrase_order.append(phrase)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Now each landmark and phrase are related by the index in each of their respective lists.**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Create a list to store the landmark dataframes and another list to store the corresponding letter in the same order.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Code phrases"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:30:18.289804Z","iopub.status.busy":"2023-06-06T00:30:18.289275Z","iopub.status.idle":"2023-06-06T00:30:18.299482Z","shell.execute_reply":"2023-06-06T00:30:18.297731Z","shell.execute_reply.started":"2023-06-06T00:30:18.289769Z"},"trusted":true},"outputs":[],"source":["#Load the character_to_prediction_index.json file\n","with open('/kaggle/input/asl-fingerspelling/character_to_prediction_index.json') as f:\n","    character_to_index = json.load(f)\n","    \n","# Create an index dictionary to characters\n","index_to_character = {v: k for k, v in character_to_index.items()}"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:30:19.178766Z","iopub.status.busy":"2023-06-06T00:30:19.178239Z","iopub.status.idle":"2023-06-06T00:30:19.189224Z","shell.execute_reply":"2023-06-06T00:30:19.187710Z","shell.execute_reply.started":"2023-06-06T00:30:19.178716Z"},"trusted":true},"outputs":[],"source":["encoded_phrases = []\n","\n","# Iterar sobre las etiquetas\n","for phrase in phrase_order:\n","    encoded_phrase = [character_to_index.get(c, 0) for c in phrase]\n","    encoded_phrases.append(encoded_phrase)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**We converted the sentences and our input data into arrays. Since each sentence has a different length, we equalized their lengths by padding them to a length of 30 characters. We filled these characters with 0, as 0 represents an empty space and relates well to the data in the landmarks where there are zeros.**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:30:20.675985Z","iopub.status.busy":"2023-06-06T00:30:20.675531Z","iopub.status.idle":"2023-06-06T00:30:20.682842Z","shell.execute_reply":"2023-06-06T00:30:20.681805Z","shell.execute_reply.started":"2023-06-06T00:30:20.675951Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_32/2265975440.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  array_phrases = np.array(encoded_phrases)\n"]}],"source":["array_phrases = np.array(encoded_phrases)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:32:58.387755Z","iopub.status.busy":"2023-06-06T00:32:58.387259Z","iopub.status.idle":"2023-06-06T00:32:58.395023Z","shell.execute_reply":"2023-06-06T00:32:58.393260Z","shell.execute_reply.started":"2023-06-06T00:32:58.387715Z"},"trusted":true},"outputs":[],"source":["from keras.utils import pad_sequences"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:33:09.297434Z","iopub.status.busy":"2023-06-06T00:33:09.297027Z","iopub.status.idle":"2023-06-06T00:33:09.309141Z","shell.execute_reply":"2023-06-06T00:33:09.307537Z","shell.execute_reply.started":"2023-06-06T00:33:09.297403Z"},"trusted":true},"outputs":[],"source":["# Realiza el padding para igualar las longitudes de las frases\n","padded_phrases = pad_sequences(array_phrases, maxlen=30, padding='post')"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:33:18.116804Z","iopub.status.busy":"2023-06-06T00:33:18.116351Z","iopub.status.idle":"2023-06-06T00:33:18.122838Z","shell.execute_reply":"2023-06-06T00:33:18.121404Z","shell.execute_reply.started":"2023-06-06T00:33:18.116771Z"},"trusted":true},"outputs":[],"source":["padded_phrases=padded_phrases.astype(np.int16)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:34:37.408920Z","iopub.status.busy":"2023-06-06T00:34:37.408472Z","iopub.status.idle":"2023-06-06T00:34:37.425094Z","shell.execute_reply":"2023-06-06T00:34:37.424074Z","shell.execute_reply.started":"2023-06-06T00:34:37.408887Z"},"trusted":true},"outputs":[],"source":["for i in range(len(landmarks_data)):\n","    landmarks_data[i].reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:35:07.240449Z","iopub.status.busy":"2023-06-06T00:35:07.239928Z","iopub.status.idle":"2023-06-06T00:35:07.730222Z","shell.execute_reply":"2023-06-06T00:35:07.728834Z","shell.execute_reply.started":"2023-06-06T00:35:07.240407Z"},"trusted":true},"outputs":[],"source":["landmarks_array = np.array(landmarks_data)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:35:10.906930Z","iopub.status.busy":"2023-06-06T00:35:10.906435Z","iopub.status.idle":"2023-06-06T00:35:10.983952Z","shell.execute_reply":"2023-06-06T00:35:10.982532Z","shell.execute_reply.started":"2023-06-06T00:35:10.906895Z"},"trusted":true},"outputs":[],"source":["landmarks_array=landmarks_array.astype(np.float32)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:35:24.757680Z","iopub.status.busy":"2023-06-06T00:35:24.756986Z","iopub.status.idle":"2023-06-06T00:35:24.768294Z","shell.execute_reply":"2023-06-06T00:35:24.766321Z","shell.execute_reply.started":"2023-06-06T00:35:24.757599Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(575, 720, 84)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["landmarks_array.shape"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:37:12.321882Z","iopub.status.busy":"2023-06-06T00:37:12.321387Z","iopub.status.idle":"2023-06-06T00:37:12.331035Z","shell.execute_reply":"2023-06-06T00:37:12.329722Z","shell.execute_reply.started":"2023-06-06T00:37:12.321846Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(575, 30)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["padded_phrases.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### We store data to save resources"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:40:51.211924Z","iopub.status.busy":"2023-06-06T00:40:51.211300Z","iopub.status.idle":"2023-06-06T00:40:51.218220Z","shell.execute_reply":"2023-06-06T00:40:51.216547Z","shell.execute_reply.started":"2023-06-06T00:40:51.211876Z"},"trusted":true},"outputs":[],"source":["import h5py"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:40:52.235559Z","iopub.status.busy":"2023-06-06T00:40:52.234471Z","iopub.status.idle":"2023-06-06T00:40:52.562592Z","shell.execute_reply":"2023-06-06T00:40:52.561218Z","shell.execute_reply.started":"2023-06-06T00:40:52.235505Z"},"trusted":true},"outputs":[],"source":["with h5py.File('/kaggle/working/landmarks_array.h5', 'w') as f:\n","    f.create_dataset('landmarks_array', data=landmarks_array)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T00:41:21.484889Z","iopub.status.busy":"2023-06-06T00:41:21.484428Z","iopub.status.idle":"2023-06-06T00:41:21.493722Z","shell.execute_reply":"2023-06-06T00:41:21.492116Z","shell.execute_reply.started":"2023-06-06T00:41:21.484856Z"},"trusted":true},"outputs":[],"source":["with h5py.File('/kaggle/working/y_data.h5', 'w') as f:\n","    f.create_dataset('y_data', data=padded_phrases)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
